{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection Demo Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Logic:\n",
    "1. Start Web Cam\n",
    "-  Detect faces using Haar Cascade\n",
    "    - return Region of Interest (ROI)\n",
    "-  Recognize attributes with pretrained CNN\n",
    "    - enlarge ROI for CNN input, since CNN is trained on the whole head, not just the face\n",
    "    - resize ROI into (200,200) to suit CNN input layers\n",
    "-  Display result in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(cap):\n",
    "    \"\"\"\n",
    "    info: get basic video info, e.g. lenght, FPS\n",
    "    input: capture object from cv.Videocapture\n",
    "    returns: basic info of the video file\n",
    "    \"\"\"\n",
    "    info_to_get = [cv.CAP_PROP_FRAME_COUNT,\n",
    "                    cv.CAP_PROP_FPS,\n",
    "                    cv.CAP_PROP_FRAME_WIDTH,\n",
    "                    cv.CAP_PROP_FRAME_HEIGHT,\n",
    "                    cv.CAP_PROP_FOURCC,\n",
    "                    cv.CAP_PROP_POS_AVI_RATIO,\n",
    "                   ]\n",
    "    \n",
    "    info = [cap.get(i) for i in info_to_get]\n",
    "    \n",
    "    # duration = 1/FPS* nb frames\n",
    "    duration = info[0]*1/info[1]\n",
    "    info.append(duration)\n",
    "    \n",
    "    # define dictionary keys\n",
    "    info_text = \"\"\"FRAME,\n",
    "    FPS,\n",
    "    WIDTH,\n",
    "    HEIGHT,\n",
    "    FOURCC,\n",
    "    POS,\n",
    "    DURATION\"\"\"\n",
    "    info_label = [i.strip() for i in info_text.split(\",\\n\")]\n",
    "    info_dict =  dict(zip(info_label,info))\n",
    "    \n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_video_plus(input_video,scale=0.5):\n",
    "    \"\"\"\n",
    "    info: Display the video in a new frame\n",
    "    input: file path of video file\n",
    "    returns: basic info of video\n",
    "    \"\"\"\n",
    "    cap = cv.VideoCapture(input_video)\n",
    "    info = get_info(cap)\n",
    "    \n",
    "    # text style config\n",
    "    color = (0,0,255) #BGR\n",
    "    text_org = (0,int(info['HEIGHT']))\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    lineTHK = 2\n",
    "    fontScale = 1\n",
    "    \n",
    "    # begining of loop\n",
    "    c=1\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        else:\n",
    "            text = f\"Frame:{c}/{int(info['FRAME'])}\"\n",
    "            cv.putText(frame,text,text_org,font,fontScale,color,lineTHK,cv.LINE_AA,bottomLeftOrigin=False)\n",
    "            out = cv.resize(frame, None , None, scale, scale)\n",
    "            cv.imshow(str(input_video),out)\n",
    "            \n",
    "            # wait key specify how many miliseconds per frame\n",
    "            # e.g. 1000ms per frame => 1 frame per second\n",
    "            # 30 fps = (1000/30**)-1\n",
    "            c+=1\n",
    "            if cv.waitKey(1000//FPS) & 0xFF == ord('q'): \n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_jpgs(input_video,show_video=False,st_end=(100,200),export_dir=\"jpgs\"):\n",
    "    \"\"\"\n",
    "    info: simple utility to cut the video into frames, put those jpg into a new folder, start folder when completed\n",
    "    input: filepath of the video\n",
    "    output: jpgs\n",
    "    \"\"\"\n",
    "    name_format = str(export_dir)+\"\\\\\"+str(input_video)+\"_Frame_\"\n",
    "    try:\n",
    "        os.makedirs(export_dir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # define start frame and end frame to cut\n",
    "    frame_st, frame_fn = st_end\n",
    "\n",
    "    c=0\n",
    "    cap = cv.VideoCapture(input_video)\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if frame_st<= c and c <frame_fn: \n",
    "            cv.imwrite(name_format+str(c)+\".jpg\",frame)\n",
    "        c+=1\n",
    "        \n",
    "        if show_video:\n",
    "            cv.imshow(str(video_raw_fp),frame)\n",
    "            if cv.waitKey(1) and 0xFF == ord('q'):\n",
    "                break\n",
    "        if c > frame_fn:\n",
    "            break\n",
    "                \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    os.startfile(export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(input_video,output_video,shape=(1280,720),FPS=30):\n",
    "    \"\"\"\n",
    "    info: save a video object\n",
    "    input: filepath of input video\n",
    "    output: saved video\n",
    "    \"\"\"\n",
    "    \n",
    "    # spent a lot of time figuring out the video encoding and format\n",
    "    # output shape must be int and equal to the input video shape\n",
    "    # working code is MJPG\n",
    "    # working file extension is .avi\n",
    "    \n",
    "    codec = \"MJPG\"\n",
    "    fourcc = cv.VideoWriter_fourcc(*codec)\n",
    "    out = cv.VideoWriter(output_video,fourcc,FPS,shape)\n",
    "    cap = cv.VideoCapture(input_video)\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if ret:\n",
    "            out.write(frame)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cut_video(input_video,output_video,st_end=(10,20),shape=(1280,720),FPS=30):\n",
    "    \"\"\"\n",
    "    info: save a video object between start time and end time\n",
    "    input: filepath of input video start time and end time\n",
    "    output: saved video\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv.VideoCapture(input_video)\n",
    "    info = get_info(cap)\n",
    "    shape = (int(info['WIDTH']),int(info['HEIGHT']))\n",
    "    FPS = info['FPS']\n",
    "             \n",
    "    codec = \"MJPG\"\n",
    "    fourcc = cv.VideoWriter_fourcc(*codec)\n",
    "    out = cv.VideoWriter(output_video,fourcc,FPS,shape)\n",
    "    \n",
    "    # convert time to frame index\n",
    "    st_frame,end_frame = st_end[0]*FPS, st_end[1]*FPS\n",
    "    \n",
    "    c = 0\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if ret:\n",
    "            if st_frame < c and c <= end_frame:\n",
    "                out.write(frame)\n",
    "            if c > end_frame: \n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        c+=1\n",
    "        \n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pic2(img,window_name=\"DISPLAY\",pos=(0,0),scale=1):\n",
    "    \"\"\"\n",
    "    use this if you want to show picture OUTSIDE the cv video capture while lopp\n",
    "    \"\"\"\n",
    "    img_out = cv.resize(img,None,None,scale,scale)\n",
    "    cv.imshow(window_name,img_out)\n",
    "    x,y = pos\n",
    "    cv.moveWindow(window_name,x,y)\n",
    "    if cv.waitKey(0) & 0xFF == ord('q'): \n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pic(img,window_name=\"DISPLAY\",pos=(0,0),scale=1):\n",
    "    \"\"\"\n",
    "    use this if you want to show picture INSIDE the cv video capture while lopp\n",
    "    \"\"\"\n",
    "    img_out = cv.resize(img,None,None,scale,scale)\n",
    "    cv.imshow(window_name,img_out)\n",
    "    x,y = pos\n",
    "    cv.moveWindow(window_name,x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained CNN model and labels detector\n",
    "model =  load_model('CNN_model\\\\faceattr_model.h5')\n",
    "df = pd.read_csv('CNN_model\\\\label_new.csv')\n",
    "labels = df.columns[2:]\n",
    "\n",
    "# load face detection haar cascade\n",
    "detect_cascade = cv.CascadeClassifier('haar_cascades\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "# start webcam\n",
    "cap = cv.VideoCapture(0)\n",
    "info = get_info(cap)\n",
    "\n",
    "# text style config\n",
    "color = (0,0,255) #BGR\n",
    "text_org = (0,int(info['HEIGHT']))\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "lineTHK = 2\n",
    "fontScale = 1\n",
    "FPS = int(info['FPS'])\n",
    "\n",
    "c=1\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: \n",
    "        break\n",
    "    else:\n",
    "        # convert frame to gray for faster calculation\n",
    "        frame_gray = cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # haar cascade block\n",
    "        sample_rate = 1\n",
    "        if c%sample_rate == 0: #detect once every 10 frames\n",
    "            ROIs = detect_cascade.detectMultiScale(frame_gray,1.1,7)\n",
    "                 \n",
    "            # skip to next frame if no face is detected\n",
    "            if len(ROIs)==0:\n",
    "                pass\n",
    "            else:\n",
    "                # draw ROI boxes\n",
    "                for (x,y,w,h) in ROIs:\n",
    "                    # draw rectangle of detected face\n",
    "                    cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    \n",
    "                    # enlarge the ROI for input of the CNN detector\n",
    "                    padding_ratio = 0.3\n",
    "                    head = frame[y-int(padding_ratio*h):y+h+int(padding_ratio*h),\n",
    "                                 x-int(padding_ratio*w):x+w+int(padding_ratio*w)]\n",
    "                    \n",
    "                    \n",
    "                    # for debugging, show the head frame for CNN model input\n",
    "#                     bbox = [x-padding_ratio*w , h+padding_ratio*h , x+(1+padding_ratio)*w , y+(1+padding_ratio)*h]\n",
    "#                     bbox = [int(i) for i in bbox]\n",
    "#                     pt1,pt2 = tuple(bbox[0:2]) , tuple(bbox[2:4])\n",
    "#                     cv.rectangle(frame,pt1,pt2,(0,0,255),2)\n",
    "                    \n",
    "                    # exception handling to avoid video from crashing when no head is detected or the input dims are wrong\n",
    "                    try:\n",
    "                        head = cv.resize(head, (200,200), interpolation = cv.INTER_AREA)\n",
    "                        \n",
    "#                         for debugging, show the head frame for CNN model input\n",
    "                        show_pic(head,window_name=str(padding_ratio),pos=(1200,0))\n",
    "\n",
    "                        # reshape input to fit NN input\n",
    "                        head_input = head.reshape(1,*head.shape)\n",
    "                        # predict\n",
    "                        y_hat = model.predict(head_input)\n",
    "\n",
    "                        results = []\n",
    "                        for i in range(len(labels)):\n",
    "                            if y_hat[0][i] > 0.8:\n",
    "                                text = f\"{labels[i]}:{y_hat[0][i]}\"\n",
    "                                results.append(text)\n",
    "                                \n",
    "                        # displaying prediction result in the video\n",
    "                        label_text = str(results).replace(\",\",\"\\n\")\n",
    "                        y0, dy = 50, 10\n",
    "                        for i, line in enumerate(label_text.split('\\n')):\n",
    "                            y_ = y0 + i*dy\n",
    "                            cv.putText(frame, line, (x, y_ ), cv.FONT_HERSHEY_SIMPLEX, 0.4, (0,0,255))\n",
    "\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "        # text block for showing the progress of video\n",
    "        text = f\"Frame:{c}/{int(info['FRAME'])}\"\n",
    "        cv.putText(frame,text,text_org,font,fontScale,\n",
    "                   color,lineTHK,cv.LINE_AA,bottomLeftOrigin=False)\n",
    "        show_pic(frame,window_name=\"FRAME\",pos=(0,0),scale=1.5)        \n",
    "        \n",
    "        c+=1\n",
    "        if cv.waitKey(int(1000/FPS)) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
